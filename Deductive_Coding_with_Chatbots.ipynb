{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"#\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import glob\n",
    "from openai import OpenAI\n",
    "\n",
    "# Set OpenAI API key\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Class Dictionary with Defined Classes\n",
    "majortopic = {\n",
    "    \"Macroeconomics\": \"Includes issues related to general domestic macroeconomic policy\",\n",
    "    \"Civil Rights\": \"Includes issues related generally to civil rights and minority rights\",\n",
    "    \"Health\": \"Includes issues related generally to health care, including appropriations for general health care government agencies\",\n",
    "    \"Agriculture\": \"Includes issues related to general agriculture policy, including appropriations for general agriculture government agencies\",\n",
    "    \"Labor\": \"Includes issues generally related to labor, employment, and pensions, including appropriations for government agencies regulating labor policy\",\n",
    "    \"Education\": \"Includes issues related to general education policy, including appropriations for government agencies regulating education policy\",\n",
    "    \"Environment\": \"Includes issues related to general environmental policy, including appropriations for government agencies regulating environmental policy\",\n",
    "    \"Energy\": \"Includes issues generally related to energy policy, including appropriations for government agencies regulating energy policy\",\n",
    "    \"Immigration\": \"Includes issues related to immigration, refugees, and citizenship\",\n",
    "    \"Transportation\": \"Includes issues related generally to transportation, including appropriations for government agencies regulating transportation policy\",\n",
    "    \"Law and Crime\": \"Includes issues related to general law, crime, and family issues\",\n",
    "    \"Social Welfare\": \"Includes issues generally related to social welfare policy\",\n",
    "    \"Housing\": \"Includes issues related generally to housing and urban affairs\",\n",
    "    \"Domestic Commerce\": \"Includes issues generally related to domestic commerce, including appropriations for government agencies regulating domestic commerce\",\n",
    "    \"Defense\": \"Includes issues related generally to defense policy, and appropriations for agencies that oversee general defense policy\",\n",
    "    \"Technology\": \"Includes issues related to general space, science, technology, and communications\",\n",
    "    \"Foreign Trade\": \"Includes issues generally related to foreign trade and appropriations for government agencies generally regulating foreign trade\",\n",
    "    \"International Affairs\": \"Includes issues related to general international affairs and foreign aid, including appropriations for general government foreign affairs agencies\",\n",
    "    \"Government Operations\": \"Includes issues related to general government operations, including appropriations for multiple government agencies\",\n",
    "    \"Public Lands\": \"Includes issues related to general public lands, water management, and territorial issues\",\n",
    "    \"Culture\": \"Includes issues related to general cultural policy issues\"\n",
    "}\n",
    "\n",
    "class_list = list(majortopic.keys())  # Extract class names dynamically\n",
    "class_definitions = majortopic  # Mapping of classes to definitions\n",
    "\n",
    "# Load datasets\n",
    "def load_data(test_file, ground_truth_file=None, text_col=\"summary\", class_col=\"major_label\"):\n",
    "    test_data = pd.read_csv(test_file)\n",
    "    ground_truth_data = pd.read_csv(ground_truth_file) if ground_truth_file else None\n",
    "    return test_data[[text_col]], ground_truth_data[[text_col, class_col]] if ground_truth_data is not None else None\n",
    "\n",
    "# OpenAI classification function\n",
    "def classify_text(text, class_list, context=\"\"):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a classification assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{context}\\nText: {text}\\nClasses: {', '.join(class_list)}\"}\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "# Retrieve file paths\n",
    "def get_file_paths(directory, pattern):\n",
    "    return glob.glob(os.path.join(directory, pattern))\n",
    "\n",
    "# Method 1: Basic Classification\n",
    "def method_1(test_files, results_dir, text_col=\"summary\"):\n",
    "    for test_file in test_files:\n",
    "        test_data, _ = load_data(test_file, text_col=text_col)\n",
    "        test_data['Predicted_Class'] = test_data[text_col].apply(lambda x: classify_text(x, class_list))\n",
    "        output_file = os.path.join(results_dir, f\"method_1_{os.path.basename(test_file)}\")\n",
    "        test_data.to_csv(output_file, index=False)\n",
    "\n",
    "# Method 2: Ground Truth Exposure\n",
    "def method_2(test_files, ground_truth_files, results_dir, text_col=\"summary\", class_col=\"major_label\"):\n",
    "    for test_file, ground_truth_file in zip(test_files, ground_truth_files):\n",
    "        test_data, ground_truth_data = load_data(test_file, ground_truth_file, text_col, class_col)\n",
    "        context = f\"Example cases with correct classifications:\\n{ground_truth_data.to_string()}\"\n",
    "        test_data['Predicted_Class'] = test_data[text_col].apply(lambda x: classify_text(x, class_list, context=context))\n",
    "        output_file = os.path.join(results_dir, f\"method_2_{os.path.basename(test_file)}\")\n",
    "        test_data.to_csv(output_file, index=False)\n",
    "\n",
    "# Method 3: Class Definitions\n",
    "def method_3(test_files, results_dir, text_col=\"summary\"):\n",
    "    context = \"\\n\".join([f\"{cls}: {class_definitions[cls]}\" for cls in class_list])\n",
    "    for test_file in test_files:\n",
    "        test_data, _ = load_data(test_file, text_col=text_col)\n",
    "        test_data['Predicted_Class'] = test_data[text_col].apply(lambda x: classify_text(x, class_list, context=context))\n",
    "        output_file = os.path.join(results_dir, f\"method_3_{os.path.basename(test_file)}\")\n",
    "        test_data.to_csv(output_file, index=False)\n",
    "\n",
    "# Method 4: Interactive Feedback\n",
    "def method_4(test_files, results_dir, text_col=\"summary\"):\n",
    "    context = \"\\n\".join([f\"{cls}: {class_definitions[cls]}\" for cls in class_list])\n",
    "    for test_file in test_files:\n",
    "        test_data, _ = load_data(test_file, text_col=text_col)\n",
    "        test_data['Predicted_Class'] = test_data[text_col].apply(lambda x: classify_text(x, class_list, context=context))\n",
    "        output_file = os.path.join(results_dir, f\"method_4_{os.path.basename(test_file)}\")\n",
    "        test_data.to_csv(output_file, index=False)\n",
    "\n",
    "# Method 5: Automated Correction\n",
    "def method_5(test_files, ground_truth_files, results_dir, text_col=\"summary\", class_col=\"major_label\"):\n",
    "    for test_file, ground_truth_file in zip(test_files, ground_truth_files):\n",
    "        test_data, ground_truth_data = load_data(test_file, ground_truth_file, text_col, class_col)\n",
    "        sample_context = ground_truth_data.head(5).to_string()\n",
    "        test_data['Predicted_Class'] = test_data[text_col].apply(lambda x: classify_text(x, class_list, context=sample_context))\n",
    "        output_file = os.path.join(results_dir, f\"method_5_{os.path.basename(test_file)}\")\n",
    "        test_data.to_csv(output_file, index=False)\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"Run classification methods on local data.\")\n",
    "    parser.add_argument(\"--data_dir\", type=str, required=True, help=\"Directory containing input data files.\")\n",
    "    parser.add_argument(\"--results_dir\", type=str, required=True, help=\"Directory to save results.\")\n",
    "    parser.add_argument(\"--method\", type=int, required=True, choices=[1, 2, 3, 4, 5], help=\"Classification method to run.\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Ensure results directory exists\n",
    "    os.makedirs(args.results_dir, exist_ok=True)\n",
    "\n",
    "    # Get file paths\n",
    "    test_files = get_file_paths(args.data_dir, \"test_*.csv\")\n",
    "    ground_truth_files = get_file_paths(args.data_dir, \"ground_truth_*.csv\")\n",
    "\n",
    "    # Run the selected method\n",
    "    if args.method == 1:\n",
    "        method_1(test_files, args.results_dir)\n",
    "    elif args.method == 2:\n",
    "        method_2(test_files, ground_truth_files, args.results_dir)\n",
    "    elif args.method == 3:\n",
    "        method_3(test_files, args.results_dir)\n",
    "    elif args.method == 4:\n",
    "        method_4(test_files, args.results_dir)\n",
    "    elif args.method == 5:\n",
    "        method_5(test_files, ground_truth_files, args.results_dir)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
