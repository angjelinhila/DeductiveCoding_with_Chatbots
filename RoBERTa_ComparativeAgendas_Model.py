# -*- coding: utf-8 -*-
"""RoBERTa.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wr2xix15umimzSsw7wch-2oos8oZuqqd
"""



# Import required libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, cohen_kappa_score
import torch
from torch.utils.data import Dataset, DataLoader
from transformers import RobertaTokenizer, RobertaForSequenceClassification, AdamW
from transformers import get_scheduler
from tqdm import tqdm

# Load dataset
#file_path = "SupremeCourt_cases.xlsx"  # Update the path as needed

from google.colab import files
uploaded = files.upload()

data = pd.read_excel("SupremeCourt_cases_.xlsx")

# Filter relevant columns and drop missing values
data = data[['summary', 'majortopic', 'subtopic']].dropna()

# Encode labels
major_encoder = LabelEncoder()
sub_encoder = LabelEncoder()
data['majortopic_encoded'] = major_encoder.fit_transform(data['majortopic'])
data['subtopic_encoded'] = sub_encoder.fit_transform(data['subtopic'])

# Split data
train_data, test_data = train_test_split(data, test_size=0.2, random_state=42, stratify=data['majortopic_encoded'])

# Load tokenizer
tokenizer = RobertaTokenizer.from_pretrained('roberta-base')

# Custom Dataset Class
class SupremeCourtDataset(Dataset):
    def __init__(self, summaries, major_labels, sub_labels, tokenizer, max_length=256):
        self.summaries = summaries
        self.major_labels = major_labels
        self.sub_labels = sub_labels
        self.tokenizer = tokenizer
        self.max_length = max_length

    def __len__(self):
        return len(self.summaries)

    def __getitem__(self, idx):
        inputs = self.tokenizer(
            self.summaries[idx],
            truncation=True,
            padding="max_length",
            max_length=self.max_length,
            return_tensors='pt'
        )
        return {
            'input_ids': inputs['input_ids'].squeeze(),
            'attention_mask': inputs['attention_mask'].squeeze(),
            'major_labels': torch.tensor(self.major_labels[idx], dtype=torch.long),
            'sub_labels': torch.tensor(self.sub_labels[idx], dtype=torch.long)
        }

# Prepare datasets
train_dataset = SupremeCourtDataset(
    train_data['summary'].tolist(),
    train_data['majortopic_encoded'].tolist(),
    train_data['subtopic_encoded'].tolist(),
    tokenizer
)

test_dataset = SupremeCourtDataset(
    test_data['summary'].tolist(),
    test_data['majortopic_encoded'].tolist(),
    test_data['subtopic_encoded'].tolist(),
    tokenizer
)

train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=8)

# Define the Model
class HierarchicalClassifier(torch.nn.Module):
    def __init__(self, model_name, major_classes, sub_classes):
        super(HierarchicalClassifier, self).__init__()
        self.roberta = RobertaForSequenceClassification.from_pretrained(model_name, num_labels=major_classes)
        self.sub_classifier = torch.nn.Linear(768, sub_classes)

    def forward(self, input_ids, attention_mask):
        outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True)
        hidden_state = outputs.hidden_states[-1][:, 0, :]  # CLS token representation
        sub_outputs = self.sub_classifier(hidden_state)
        return outputs.logits, sub_outputs

# Instantiate the Model
device = "cuda" if torch.cuda.is_available() else "cpu"
major_classes = len(major_encoder.classes_)
sub_classes = len(sub_encoder.classes_)
model = HierarchicalClassifier("roberta-base", major_classes, sub_classes).to(device)

# Optimizer and Scheduler
optimizer = AdamW(model.parameters(), lr=5e-5)
num_training_steps = len(train_loader) * 5  # 3 epochs
lr_scheduler = get_scheduler("linear", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)

# Training Loop
def train(model, dataloader, optimizer, lr_scheduler):
    model.train()
    for batch in tqdm(dataloader, desc="Training"):
        batch = {k: v.to(device) for k, v in batch.items()}
        optimizer.zero_grad()
        major_outputs, sub_outputs = model(batch['input_ids'], batch['attention_mask'])
        loss_major = torch.nn.CrossEntropyLoss()(major_outputs, batch['major_labels'])
        loss_sub = torch.nn.CrossEntropyLoss()(sub_outputs, batch['sub_labels'])
        loss = loss_major + loss_sub
        loss.backward()
        optimizer.step()
        lr_scheduler.step()

# Evaluation Function
def evaluate(model, dataloader):
    model.eval()
    major_preds, sub_preds, major_labels, sub_labels = [], [], [], []
    with torch.no_grad():
        for batch in tqdm(dataloader, desc="Evaluating"):
            batch = {k: v.to(device) for k, v in batch.items()}
            major_outputs, sub_outputs = model(batch['input_ids'], batch['attention_mask'])
            major_preds.extend(torch.argmax(major_outputs, dim=1).cpu().tolist())
            sub_preds.extend(torch.argmax(sub_outputs, dim=1).cpu().tolist())
            major_labels.extend(batch['major_labels'].cpu().tolist())
            sub_labels.extend(batch['sub_labels'].cpu().tolist())
    return major_labels, major_preds, sub_labels, sub_preds

# Train and Evaluate
for epoch in range(5):
    print(f"Epoch {epoch+1}")
    train(model, train_loader, optimizer, lr_scheduler)

# Evaluation Results
major_labels, major_preds, sub_labels, sub_preds = evaluate(model, test_loader)

# Classification Reports
print("Classification Report for Major Topics:")
print(classification_report(major_labels, major_preds, target_names=major_encoder.classes_))
print("Cohen's Kappa for Major Topics:", cohen_kappa_score(major_labels, major_preds))

print("\nClassification Report for Subtopics:")
print(classification_report(sub_labels, sub_preds, target_names=sub_encoder.classes_))
print("Cohen's Kappa for Subtopics:", cohen_kappa_score(sub_labels, sub_preds))

from sklearn.metrics import classification_report, cohen_kappa_score

# Evaluation Results
major_labels, major_preds, sub_labels, sub_preds = evaluate(model, test_loader)

# Convert numpy.int64 to native Python int for labels and predictions
major_labels = [int(label) for label in major_labels]
major_preds = [int(pred) for pred in major_preds]
sub_labels = [int(label) for label in sub_labels]
sub_preds = [int(pred) for pred in sub_preds]

# Convert class names to strings
major_classes = [str(cls) for cls in major_encoder.classes_]
sub_classes = [str(cls) for cls in sub_encoder.classes_]

# Filter predictions to match valid classes
valid_major_labels = [label for label in major_labels if label in range(len(major_classes))]
valid_major_preds = [pred for pred, label in zip(major_preds, major_labels) if label in range(len(major_classes))]

valid_sub_labels = [label for label in sub_labels if label in range(len(sub_classes))]
valid_sub_preds = [pred for pred, label in zip(sub_preds, sub_labels) if label in range(len(sub_classes))]

# Classification Reports
print("Classification Report for Major Topics:")
print(classification_report(valid_major_labels, valid_major_preds, target_names=major_classes, zero_division=0))
print("Cohen's Kappa for Major Topics:", cohen_kappa_score(valid_major_labels, valid_major_preds))


# Align sub_labels and sub_preds
valid_sub_labels, valid_sub_preds = zip(*[
    (label, pred) for label, pred in zip(sub_labels, sub_preds)
    if label in range(len(sub_classes))
])

# Classification Reports
print("Classification Report for Subtopics:")
print(classification_report(valid_sub_labels, valid_sub_preds, target_names=sub_classes, zero_division=0))

print("Cohen's Kappa for Subtopics:", cohen_kappa_score(valid_sub_labels, valid_sub_preds))

sub_classes = [str(cls) for cls in sub_encoder.classes_]

# Get unique labels present in the predictions and ground truth
unique_sub_labels = sorted(set(valid_sub_labels) | set(valid_sub_preds))

# Classification Report for Subtopics
print("Classification Report for Subtopics:")
print(classification_report(
    valid_sub_labels,
    valid_sub_preds,
    target_names=[sub_classes[i] for i in unique_sub_labels],  # Map only existing classes
    labels=unique_sub_labels,  # Use only valid class indices
    zero_division=0
))

print("Cohen's Kappa for Subtopics:", cohen_kappa_score(valid_sub_labels, valid_sub_preds))

#Update the evaluate function to calculate and return softmax probabilities for the major classes:
from torch.nn.functional import softmax

def evaluate_with_softmax(model, dataloader):
    model.eval()
    major_preds, sub_preds, major_labels, sub_labels = [], [], [], []
    major_probs = []  # Store softmax probabilities for major classes
    with torch.no_grad():
        for batch in tqdm(dataloader, desc="Evaluating with Softmax"):
            batch = {k: v.to(device) for k, v in batch.items()}
            major_outputs, sub_outputs = model(batch['input_ids'], batch['attention_mask'])

            # Apply softmax to major outputs
            softmax_major = softmax(major_outputs, dim=1)
            major_probs.extend(softmax_major.cpu().tolist())  # Convert to list and store

            major_preds.extend(torch.argmax(major_outputs, dim=1).cpu().tolist())
            sub_preds.extend(torch.argmax(sub_outputs, dim=1).cpu().tolist())
            major_labels.extend(batch['major_labels'].cpu().tolist())
            sub_labels.extend(batch['sub_labels'].cpu().tolist())
    return major_labels, major_preds, sub_labels, sub_preds, major_probs

# Evaluate model
major_labels, major_preds, sub_labels, sub_preds, major_probs = evaluate_with_softmax(model, test_loader)

import numpy as np

def analyze_top_n(major_labels, major_probs, top_n=3):
    correct_in_top_n = 0
    total = len(major_labels)

    for label, probs in zip(major_labels, major_probs):
        top_n_indices = np.argsort(probs)[-top_n:][::-1]  # Get indices of top-N probabilities
        if label in top_n_indices:
            correct_in_top_n += 1

    accuracy_top_n = correct_in_top_n / total
    print(f"Accuracy with Top-{top_n}: {accuracy_top_n:.2%}")

# Analyze top-3 probabilities
analyze_top_n(major_labels, major_probs, top_n=3)
import matplotlib.pyplot as plt

def visualize_softmax_distribution(major_labels, major_preds, major_probs, class_names, num_samples=5):
    misclassified_indices = [i for i, (true, pred) in enumerate(zip(major_labels, major_preds)) if true != pred]
    samples = np.random.choice(misclassified_indices, num_samples, replace=False)

    for i in samples:
        plt.figure(figsize=(10, 5))
        plt.bar(range(len(major_probs[i])), major_probs[i])
        plt.title(f"Sample {i}: True={class_names[major_labels[i]]}, Pred={class_names[major_preds[i]]}")
        plt.xlabel("Class Index")
        plt.ylabel("Probability")
        plt.show()

# Call visualization
visualize_softmax_distribution(major_labels, major_preds, major_probs, major_encoder.classes_)